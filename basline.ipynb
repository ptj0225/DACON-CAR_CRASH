{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import util\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':380,\n",
    "    'EPOCHS':4,\n",
    "    'LEARNING_RATE':5e-5,\n",
    "    'BATCH_SIZE':12,\n",
    "    'SEED':41,\n",
    "    'ALPHA': 0.5\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b4(pretrained=True)\n",
    "        self.backbone.classifier[-2] = nn.Dropout(0.7)\n",
    "        self.backbone.classifier[-1] = nn.Linear(1792, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_pic.csv', index_col=0)\n",
    "df_labeled = df[df.loc[:, 'weather'] != -1]\n",
    "\n",
    "train_unlabeld = df[df.loc[:, 'weather'] == -1]\n",
    "train_labeled = df_labeled[: int(len(df_labeled) * 0.8)]\n",
    "valid = df_labeled[int(len(df_labeled) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path_list, label_list, tfms):\n",
    "        self.path_list = path_list\n",
    "        self.label_list = label_list\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.path_list[index])\n",
    "        if self.tfms is not None:\n",
    "            image = self.tfms(image = image)['image']\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = np.zeros(5)\n",
    "            label[int(self.label_list[index][0])] = 1\n",
    "            label[3 + int(self.label_list[index][1])] = 1\n",
    "            label = np.float32(label)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms_train = A.Compose([A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.ColorJitter(p=0.5),\n",
    "                        A.Rotate((-30,30), p=0.5),\n",
    "                        A.Normalize(mean=(0.3192, 0.3201, 0.3083), std=(0.2132, 0.2072, 0.2059)),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "tfms_test = A.Compose([A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "                        A.Normalize(mean=(0.3192, 0.3201, 0.3083), std=(0.2132, 0.2072, 0.2059)),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "train_dataset = util.CustomDataset(train_labeled['path'].values, train_labeled.loc[:, ['weather', 'timing']].values, tfms_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "\n",
    "train_unlabeld_dataset = util.CustomDataset(train_unlabeld['path'].values, None, tfms_test)\n",
    "train_loader_unlabeled = DataLoader(train_unlabeld_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "\n",
    "valid_dataset = util.CustomDataset(valid['path'].values, valid.loc[:, ['weather', 'timing']].values, tfms_test)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_loss = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            output = torch.concat([F.softmax(output[:, :3]), F.softmax(output[:, 3:])], dim=1)\n",
    "            loss = criterion(output, target=labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            if len(train_loss) >= 5:\n",
    "                print(\"\\rtrain_loss: {0}\".format(round(np.mean(train_loss[-5:]), 5)), end=\"\")\n",
    "        _val_loss = validation(model, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_loss)\n",
    "            \n",
    "        if best_val_loss < _val_loss:\n",
    "            best_val_acc = _val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, best_val_loss\n",
    "\n",
    "def validation(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probs = model(imgs)\n",
    "            \n",
    "            loss = criterion(F.softmax(input=probs), target=labels)\n",
    "            \n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "    print(_val_loss)\n",
    "    return _val_loss\n",
    "\n",
    "def psudo_label(model, train_unlabeld, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    train_dataset = CustomDataset(train_unlabeld.loc[:, 'path'].values, None, tfms_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 1, shuffle=False, num_workers=0)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            output = model(imgs)\n",
    "            output = output.to('cpu').numpy()\n",
    "            pred = np.stack([np.argmax(output[:, :3], axis=1),\n",
    "                             np.argmax(output[:, 3:], axis=1)], axis = 1)\n",
    "            preds += list(pred)\n",
    "    return np.array(preds, int)\n",
    "\n",
    "def detect_outliers(model, train_labeled, threshold, device):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    train_labeled_updated = copy.deepcopy(train_labeled)\n",
    "    train_labeled_outlier = copy.deepcopy(train_labeled)\n",
    "    train_dataset = CustomDataset(train_labeled.loc[:, 'path'].values, train_labeled.loc[:, ['weather', 'timing']].values, tfms_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 1, shuffle=False, num_workers=0)\n",
    "\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    with torch.no_grad():\n",
    "        index = 0\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            output = model(imgs)\n",
    "            output = torch.concat([F.softmax(output[:, :3]), F.softmax(output[:, 3:])], dim=1)\n",
    "            loss = criterion(output, target=labels)\n",
    "            result.append((loss.item(), index))\n",
    "            index += 1\n",
    "\n",
    "    result = sorted(result, reverse=True)\n",
    "    for loss, index in result:\n",
    "        if loss < max(result[len(result)//10][0], threshold):\n",
    "            train_labeled_outlier = train_labeled_outlier.drop(index = train_labeled.index[index])\n",
    "        else:\n",
    "            train_labeled_updated = train_labeled_updated.drop(index = train_labeled.index[index])\n",
    "    return train_labeled_updated, train_labeled_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labeled data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06bfae90e4f49fca880679680b3ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.09522"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ef3b64a9cd42a6a754b43c894d959c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4806498363711731\n",
      "Epoch [1], Train Loss : [0.20631] Val Loss : [0.48065]\n",
      "detecting outliers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115cea9d12974abea434e231200cfb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "best_val_loss = 0\n",
    "train_labeled_updated = copy.deepcopy(train_labeled)\n",
    "train_unlabeld_updated = copy.deepcopy(train_unlabeld)\n",
    "for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "    #labeled data 학습\n",
    "    print(\"training labeled data...\")\n",
    "    train_dataset = util.CustomDataset(train_labeled_updated['path'].values, train_labeled_updated.loc[:, ['weather', 'timing']].values, tfms_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "\n",
    "    infer_model, val_loss = train(model=model, optimizer=optimizer, epochs=1, train_loader=train_loader, val_loader=valid_loader, scheduler=scheduler, device=device)\n",
    "    if best_val_loss < val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "    #labeled data 이상치 제거\n",
    "    print(\"detecting outliers...\")\n",
    "    train_labeled_updated , train_labeled_outlier = detect_outliers(model, train_labeled, threshold = CFG['ALPHA'], device=device)\n",
    "    print(len(train_labeled_outlier), 'data removed from', len(train_labeled))\n",
    "    train_unlabeld_updated = pd.concat([train_labeled_outlier, train_unlabeld])\n",
    "\n",
    "    #psudo labeling\n",
    "    print(\"psudo labeling...\")\n",
    "    psudo_labeled = psudo_label(model, train_unlabeld_updated, device)\n",
    "\n",
    "    # create concat loader\n",
    "    unlabeled_dataset = util.CustomDataset(train_unlabeld_updated['path'].values, psudo_labeled, tfms_test)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "\n",
    "    #labeled, unlabeled data 학습\n",
    "    print(\"training unlabeled data...\")\n",
    "    infer_model, val_loss = train(model=model, optimizer=optimizer, epochs=1, train_loader=unlabeled_loader, val_loader=valid_loader, scheduler=scheduler, device=device)\n",
    "    if best_val_loss < val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2076a387d2eeee7d098e4cccefb973249bebb4fa144919220ce31f67b8bf2cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
